{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 5: Normalización \n",
    "\n",
    "Como bien dice el nombre del fichero, lo que se busca es normalizar cada una de las variables que van a conformar el ```input``` de nuestra red. Para ello, utilizaremos una normalización min-max del 0 al 1 y guardaremos sus factores de escala para una futura desnormalización.\n",
    "\n",
    "#### 5.1. Normalización conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "path_tr= \"../../parches_winscp/bicubic_32_32/190824_16_tr/raw/\"\n",
    "\n",
    "var_names = [\"u10_input\", \"u10_target\",\"v10_input\", \"v10_target\",\n",
    "             \"t2_input\", \"th2_input\", \"psfc_input\", \"pblh_input\", \n",
    "             \"xland_input\", \"hgt_input\", \"aspect_input\", \"slope_input\",\n",
    "             \"EmaxU_input\", \"EmaxV_input\", \"EminU_input\", \"EminV_input\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u10_input': [-24.035671, 19.812311],\n",
       " 'u10_target': [-31.29994, 31.842432],\n",
       " 'v10_input': [-20.810207, 14.965427],\n",
       " 'v10_target': [-30.851156, 23.74102],\n",
       " 't2_input': [257.75668, 298.89575],\n",
       " 'th2_input': [267.9052, 303.7989],\n",
       " 'psfc_input': [82636.02, 103507.99],\n",
       " 'pblh_input': [-273.23758, 2129.6934],\n",
       " 'xland_input': [0.761478, 2.2074287],\n",
       " 'hgt_input': [-22.215477, 1449.4507],\n",
       " 'aspect_input': [0.0, 360.0],\n",
       " 'slope_input': [0.0, 89.29281],\n",
       " 'EmaxU_input': [-23.877573, 17.691437],\n",
       " 'EmaxV_input': [-19.628057, 13.7348995],\n",
       " 'EminU_input': [-17.493675, 23.955181],\n",
       " 'EminV_input': [-13.671599, 19.655247]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carpeta_tr= '../../parches_winscp/bicubic_32_32/190824_16_tr/norm/'\n",
    "factores_escala = {} \n",
    "\n",
    "for name in var_names: \n",
    "              \n",
    "    array_tr = tf.convert_to_tensor(np.load(f\"{path_tr}{name}_raw_190824_16_tr.npy\"))\n",
    "    factor_min = tf.reduce_min(array_tr)\n",
    "    factor_max = tf.reduce_max(array_tr)\n",
    "\n",
    "    array_norm_tr = (array_tr - factor_min) / (factor_max - factor_min)\n",
    "    np.save(carpeta_tr+name+\"_norm_190824_16_tr.npy\", array_norm_tr)\n",
    "    \n",
    "    factores_escala[name] = [factor_min.numpy(), factor_max.numpy() ]\n",
    "\n",
    "factores_escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('extra/factores/factores_escala_190824_16.pkl', 'wb') as archivo:\n",
    "    pickle.dump(factores_escala, archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Normalización conjunto de validación usando factores de escala anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_va   = \"../../parches_winscp/bicubic_32_32/190824_16_va/raw/\"\n",
    "carpeta_va= '../../parches_winscp/bicubic_32_32/190824_16_va/norm/'\n",
    "\n",
    "for name in var_names: \n",
    "    array_va = tf.convert_to_tensor(np.load(f\"{path_va}{name}_raw_190824_16_va.npy\"))\n",
    "    array_norm_va = (array_va - factores_escala[name][0]) / (factores_escala[name][1] - factores_escala[name][0])\n",
    "    np.save(carpeta_va+name+\"_norm_190824_16_va.npy\", array_norm_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Chequeo desnormalización\n",
    "Tanto para el conjunto de entrenamiento como de validación se observan diferencias asociadas al punto flotante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dif. máx. array og versus desnorm u10_input 2.861023e-06\n",
      "Dif. máx. array og versus desnorm u10_target 2.861023e-06\n",
      "Dif. máx. array og versus desnorm v10_input 2.861023e-06\n",
      "Dif. máx. array og versus desnorm v10_target 3.8146973e-06\n",
      "Dif. máx. array og versus desnorm t2_input 0.0\n",
      "Dif. máx. array og versus desnorm th2_input 0.0\n",
      "Dif. máx. array og versus desnorm psfc_input 0.0\n",
      "Dif. máx. array og versus desnorm pblh_input 0.00018310547\n",
      "Dif. máx. array og versus desnorm xland_input 1.1920929e-07\n",
      "Dif. máx. array og versus desnorm hgt_input 6.1035156e-05\n",
      "Dif. máx. array og versus desnorm aspect_input 1.5258789e-05\n",
      "Dif. máx. array og versus desnorm slope_input 3.8146973e-06\n",
      "Dif. máx. array og versus desnorm EmaxU_input 2.861023e-06\n",
      "Dif. máx. array og versus desnorm EmaxV_input 2.861023e-06\n",
      "Dif. máx. array og versus desnorm EminU_input 2.861023e-06\n",
      "Dif. máx. array og versus desnorm EminV_input 3.8146973e-06\n"
     ]
    }
   ],
   "source": [
    "for var in var_names:\n",
    "\n",
    "    array_norm   = tf.convert_to_tensor(np.load(f\"{carpeta_tr}{var}_norm_190824_16_tr.npy\"))\n",
    "    array_desnorm =( array_norm * (factores_escala[var][1]- factores_escala[var][0])  ) + factores_escala[var][0]\n",
    "    array_original = tf.convert_to_tensor(np.load(f\"{path_tr}{var}_raw_190824_16_tr.npy\"))\n",
    "\n",
    "    print(f\"Dif. máx. array og versus desnorm {var}\", np.max( np.abs( array_desnorm - array_original)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el conjunto de validación: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dif. máx. array og versus desnorm u10_input 2.861023e-06\n",
      "Dif. máx. array og versus desnorm u10_target 7.6293945e-06\n",
      "Dif. máx. array og versus desnorm v10_input 2.861023e-06\n",
      "Dif. máx. array og versus desnorm v10_target 3.8146973e-06\n",
      "Dif. máx. array og versus desnorm t2_input 0.0\n",
      "Dif. máx. array og versus desnorm th2_input 0.0\n",
      "Dif. máx. array og versus desnorm psfc_input 0.0\n",
      "Dif. máx. array og versus desnorm pblh_input 0.00024414062\n",
      "Dif. máx. array og versus desnorm xland_input 1.1920929e-07\n",
      "Dif. máx. array og versus desnorm hgt_input 6.1035156e-05\n",
      "Dif. máx. array og versus desnorm aspect_input 1.5258789e-05\n",
      "Dif. máx. array og versus desnorm slope_input 3.8146973e-06\n",
      "Dif. máx. array og versus desnorm EmaxU_input 5.722046e-06\n",
      "Dif. máx. array og versus desnorm EmaxV_input 2.861023e-06\n",
      "Dif. máx. array og versus desnorm EminU_input 2.861023e-06\n",
      "Dif. máx. array og versus desnorm EminV_input 5.722046e-06\n"
     ]
    }
   ],
   "source": [
    "for var in var_names:\n",
    "\n",
    "    array_norm   = tf.convert_to_tensor(np.load(f\"{carpeta_va}{var}_norm_190824_16_va.npy\"))\n",
    "    array_desnorm =( array_norm * (factores_escala[var][1]- factores_escala[var][0])  ) + factores_escala[var][0]\n",
    "    array_original = tf.convert_to_tensor(np.load(f\"{path_va}{var}_raw_190824_16_va.npy\"))\n",
    "\n",
    "    print(f\"Dif. máx. array og versus desnorm {var}\", np.max( np.abs( array_desnorm - array_original)) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrf_python_build",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
